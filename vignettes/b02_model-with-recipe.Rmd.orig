---
title: "Using recipes in tidyflow"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{model-with-recipe}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "recipes-"
  ## eval = FALSE
)
```

This vignette aims to exemplify how you can use recipes within a `tidyflow`.

A tidyflow is a bundle of steps that allow you to bundle together your data, splitting, resampling, preprocessing, modeling, and grid search. For preprocessing your data, the `tidymodels` ecosystem contains the `recipes` package. This package allows to create very concise and clean pipelines of transforming your data. Let's create a very simple recipe that takes the logarithm of the variable `qsec`:

```{r}
library(tidymodels)
library(tidyflow)
```

```{r, echo = FALSE, message = FALSE}
library(rsample)
library(tune)
library(parsnip)
library(rsample)
library(dials)
library(tidyflow)
```

```{r }
rcp <-
  mtcars %>%
  recipe(mpg ~ .) %>%
  step_log(qsec)
  
rcp
```

The recipe contains the model formula (`mpg ~ .`) and a preprocessing step `step_log(qsec)`. How do we incorporate this in our `tidyflow`? We use `plug_recipe` but we need to change this recipe to be a formula:

```{r}
rcp <-
  ~ .x %>%
    recipe(mpg ~ .) %>%
    step_log(qsec)

tflow <-
  mtcars %>%
  tidyflow(seed = 5131) %>%
  plug_recipe(rcp)

tflow
```

Did you notice that we replace `mtcars` with `.x` and that `.x` has a `~` in front of it? Those are the only two things that changes from our previous recipe. `tidyflow` already knows that `.x` will be the placeholder for the data and will figure out where to place the recipe in the order of execution. 

Having said this, there's no need to specify a formula for the model definition: the recipe already contains this formula! So let's split the data into training and testing and fit a linear regression:

```{r}
tflow <-
  tflow %>%
  plug_split(initial_split) %>%
  plug_model(linear_reg() %>% set_engine("lm"))

final_model <- tflow %>% fit()

final_model %>%
  pull_tflow_fit()
```

Defining your preprocessing steps in the recipe has several advantages among which are that the `tidyflow` takes care of applying these preprocessing steps in the training/testing data automatically. You can automatically predict on the training data and expect the `tidyflow` to calculate the log of `qsec` automatically:

```{r}
final_model %>%
  predict_training()
```

Note that the `qsec` column here is untransformed but the model used to predict on the new `.pred` column was indeed logged. How can you be sure? You can extract the transformed training data with `pull_tflow_training` with `prep = TRUE`:

```{r}
final_model %>%
  pull_tflow_training(prep = TRUE)
```

One drawback from the print out of the `tidyflow` is that you can really see the type of preprocessing that was used for fitting the model. `pull_tflow_prepped_recipe` returns the fitted recipe on the final model and contains all the steps used in the recipe:

```{r}
final_model %>%
  pull_tflow_prepped_recipe()
```

Another advantage of a recipe preprocessing step is that it allows to perform a grid search on values defined in the preprocessing. For example, suppose we want to calculate the polynomial of `sec`. We could try `qsec^2`, `qsec^3`, etc... Until we find a polynomial that maximizes our predictive accuracy. Recipes accept an object called `tune` that signals that we will try many values for a particular argument (polynomials in this case). If you specify a `plug_split`, `tidyflow` can figure out some possible values to use are run the entire grid search for you. For example:

```{r}
# New recipe that will try many values for degree
# degree here means the polynomial degree.
# For example, qsec^2, qsec^3, etc...
rcp <-
  ~ .x %>%
    recipe(mpg ~ .) %>%
    step_poly(qsec, degree = tune())

final_model <-
  tflow %>% # Reuse the same tidyflow from before
  replace_recipe(rcp) %>% # Replace the recipe with the new one
  plug_resample(vfold_cv) %>% # Plug in the cross-validation for grid search
  plug_grid(grid_regular) %>% # Plug in the type of grid search
  fit()

final_model
```

The result is now a tuning grid and **not** a final model. As expected, this is because `tidyflow` already fit many models using different values for `degree`. We can explore the performance of the model with this model.

```{r, grid_search_recipe}
final_model %>%
  pull_tflow_fit_tuning() %>%
  autoplot()
```

The lowest error for both the $RMSE$ and the $R^2$ seems to be a model of `degree = 2`. We can specify this directly into `complete_tflow` or just allow `complete_tflow` to determine this for you:

```{r}
# Manual approach
best_model <- final_model %>% complete_tflow(best_params = data.frame(degree = 2))

# Allow `complete_tflow` to determine this for you
best_model <- final_model %>% complete_tflow(metric = "rmse")

best_model %>%
  predict_training()
```

The `recipes` package and `tidymodels` and very powerful tools for doing machine learning. In this vignette, I tried to extend their work by providing a unified interface for working with `tidymodels` that uses the recipe framework bundled together with all the other common machine learning steps.

Want to see tidyflow and recipes in action? The `tidymodels` team has a vignette showcasing how to use `recipes` and `tidymodels` [here](https://www.tidymodels.org/start/recipes/). I've adapted their code to fully run within a `tidyflow` workflow. Here's the replication code:

```{r, eval = FALSE}
library(tidymodels)
library(tidyflow)
library(nycflights13)

## Start initial preprocessing
flight_data <- 
  flights %>% 
  mutate(
    # Convert the arrival delay to a factor
    arr_delay = ifelse(arr_delay >= 30, "late", "on_time"),
    arr_delay = factor(arr_delay),
    # We will use the date (not date-time) in the recipe below
    date = as.Date(time_hour)
  ) %>% 
  # Include the weather data
  inner_join(weather, by = c("origin", "time_hour")) %>% 
  # Only retain the specific columns we will use
  select(dep_time, flight, origin, dest, air_time, distance, 
         carrier, date, arr_delay, time_hour) %>% 
  # Exclude missing data
  na.omit() %>% 
  # For creating models, it is better to have qualitative columns
  # encoded as factors (instead of character strings)
  mutate_if(is.character, as.factor)

## End initial preprocessing

# Model formula and recipe preprocessing
flight_rec <-
  ~ .x %>%
    recipe(arr_delay ~ .) %>% 
    update_role(flight, time_hour, new_role = "ID") %>% 
    step_date(date, features = c("dow", "month")) %>% 
    step_holiday(date, holidays = timeDate::listHolidays("US")) %>% 
    step_rm(date) %>% 
    step_dummy(all_nominal(), -all_outcomes()) %>% 
    step_zv(all_predictors())

# tidyflow preparation with the recipe
tflow <-
  flight_data %>%
  tidyflow(seed = 555) %>%
  plug_split(initial_split, prop = 3/4) %>%
  plug_recipe(flight_rec) %>%
  plug_model(logistic_reg() %>% set_engine("glm"))

# Fit final model
flights_fit <- fit(tflow)

# Predict on testing and evaluate a `roc_curve`
flights_fit %>%
  predict_testing(type = "prob") %>%
  roc_curve(truth = arr_delay, .pred_late) %>% 
  autoplot()
```

